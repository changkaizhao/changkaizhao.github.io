---
layout: post
title: '二项分布与Beta分布'
subtitle: '机器学习之概率基础一'
date: 2020-11-09
categories: 机器学习 概率
cover: 'http://www.digitbrain.science/images/ml_tutorial/cover01.png'
tags: 贝叶斯 共轭先验 二项分布 Beta分布
---

## 抛硬币

抛硬币游戏中，会产生两种结果：**正面**和**背面**，可以用随机变量$$x$$表示。因此$$x\in\{0,1\}$$，表示抛硬币结果不是正面就是反面。其中$$0$$表示**正面**，$$1$$表示**背面**。

我们知道一个均匀的硬币随机抛出**正面**的概率为$$0.5$$, 如果硬币不够均匀，则这个概率值会改变。可定义抛出**正面**的概率为$$\mu$$，抛出**背面**的概率为$$1-\mu$$, $$0\le\mu\le1$$。

$$p(x=1\mid\mu)=\mu$$  

$$p(x=0\mid\mu)=1-\mu$$  


因此，$$x$$的概率分布可表示为**伯努利分布(Bernoulli distribution)**:  

$$Bern(x\mid\mu)=\mu^x(1-\mu)^{1-x}$$


其**期望**和**方差**分别为:  

$$\mathbb{E}[x]=\mu$$  

$$var[x]=\mu(1-\mu)$$  



## 参数估计

我们抛一枚捡到的硬币$$N$$次(***捡到可以理解为对这个硬币是不太了解的，即对其抛出正面的概率未知***)，就得到了$$N$$个样本数据$$\mathcal{D}$$.  
例如: 当$$N=10$$即进行了10次抛硬币,但是每次抛硬币出现**正面**的概率$$\mu$$是未知的，我们需要通过这10次抛硬币的数据样本来估计$$\mu$$值。样本数据$$\mathcal{D}$$如下:   


| $$n$$ | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |
|:-----:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
| $$x$$ | 0 | 1 | 1 | 0 | 0 | 0 | 1 | 0 | 1 | 1 |

聪明的你肯定会马上想到这个估计值，用**正面**出现的次数除以总游戏的次数$$N$$, 便可得到$$\mu$$。
没错，其背后的原理我们可以用**最大似然估计**来解释。首先定义**似然函数**为如下:

 $$p(\mathcal{D}\mid\mu)=\prod_{n=1}^N\mu^{x_n}(1-\mu)^{1-x_n}$$ 

其表示给定某个参数$$\mu$$的条件下，出现样本数据$$\mathcal{D}$$的概率。所以这个概率值越大，其$$\mu$$越接近真实的参数值。

计算**似然函数**的最大值可以采用取对数的方法，将连乘形式转化为连加方便计算。  

 $$\mathrm{ln}p(\mathcal{D}\mid\mu)=\sum_{n=1}^N\mathrm{ln}p(x_n\mid\mu)=\sum_{n=1}^N\{x_n\mathrm{ln}\mu+(1-x_n)\mathrm{ln}(1-\mu)\}$$


最后可计算得到，当$$\mu$$有如下值时，上式取得最大值。  

 $$\mu_{\mathrm{ML}}=\frac{1}{N}\sum_{n=1}^Nx_n$$


 由于随机变量$$x\in\{0,1\}$$， 可进一步简化为:

 $$\mu_{\mathrm{ML}}=\frac{m}{N}$$

 式中$$m$$表示数据样本中出现正面的次数，和你的直觉是一样的结果。




（continue...）

## 二项分布

## Beta分布
<img src="https://www.digitbrain.science/images/ml_tutorial/test.svg">

<svg width="400" height=300>
    <circle cx="150" cy="100" r="10" fill="blue"/>
</svg>
