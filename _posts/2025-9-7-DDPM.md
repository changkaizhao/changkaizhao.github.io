---
layout: post
title: DDPM 详解
tags: DDPM
---

# DDPM 论文的 Background（第 2 节）逐式讲解（含公式直观解释）

下面把 Ho 等人在 *Denoising Diffusion Probabilistic Models* 的 **Background** 关键公式逐条拆开讲清：模型是怎样定义的、训练目标从哪里来、以及每个量的物理/统计意义。为便于对照，我按论文中的编号 (1)–(7) 说明，并给出推导直觉。

---

## 1) 潜变量建模与**逆过程**（reverse process）：式 (1)

**设定.** 把数据 $$x_0$$ 的生成视为一个马尔可夫链从高斯“纯噪声” $$x_T\sim\mathcal N(0,I)$$ 一步步**去噪**得到 $$x_0$$。整条链的联合分布写成

$$
p_\theta(x_{0:T}) \;=\; p(x_T)\prod_{t=1}^{T} p_\theta(x_{t-1}\mid x_t),
$$

且每一步的条件分布都设为高斯：

$$
p_\theta(x_{t-1}\mid x_t) \;=\; \mathcal N\!\big(x_{t-1};\, \mu_\theta(x_t,t),\, \Sigma_\theta(x_t,t)\big).
$$

这就是“**逆过程**”：学一个从噪声往数据的去噪马尔可夫链。高斯假设让训练/推断都可微、可闭式计算。

---

## 2) **正向扩散**（forward / diffusion process）：式 (2)

**思想.** 训练时需要一个易算的“近似后验” $$q(x_{1:T}\mid x_0)$$ 来做变分下界。DDPM 直接把它**固定**成“逐步加高斯噪声”的马尔可夫链（不学）：

$$
q(x_{1:T}\mid x_0)=\prod_{t=1}^{T} q(x_t\mid x_{t-1}),\qquad
q(x_t\mid x_{t-1})=\mathcal N\!\big(\sqrt{1-\beta_t}\,x_{t-1},\, \beta_t I\big),
$$

其中 $$\{\beta_t\}_{t=1}^T$$ 是**噪声日程**（variance schedule）。$$\beta_t$$ 小就表示这一步只加一点噪声。

为什么这么设？因为当 $$\beta_t$$ 足够小，正向的高斯条件和逆向的高斯条件**同形**（functional form 相近），便于学到一个形状匹配的去噪条件分布。

---

## 3) 训练目标：**负对数似然的变分上界** $$L$$：式 (3)

对任意 $$x_0\sim q(x_0)$$，有

$$
\mathbb E[-\log p_\theta(x_0)]
\;\le\;
\mathbb E_{q}\!\left[-\log\frac{p_\theta(x_{0:T})}{q(x_{1:T}\mid x_0)}\right]
\;=:\; L.
$$

把 (1)(2) 代入并展开，得到

$$
L=\mathbb E_q\!\left[
-\log p(x_T)\;-\sum_{t\ge1}\log\frac{p_\theta(x_{t-1}\mid x_t)}{q(x_t\mid x_{t-1})}
\right].
$$

直觉上，这是“用我们学的逆过程去解释由扩散过程产生的样本”的编码长度（越小越好）。

---

## 4) 正向过程的**闭式边缘**：式 (4)

引入 $$\alpha_t:=1-\beta_t$$，以及 $$\bar\alpha_t:=\prod_{s=1}^t \alpha_s$$。把 (2) 反复代入可得一个非常重要的闭式式子：

$$
q(x_t\mid x_0)=\mathcal N\!\big(\sqrt{\bar\alpha_t}\,x_0,\; (1-\bar\alpha_t)I\big).
$$

**重参数化**写法尤其直观：

$$
x_t \;=\; \sqrt{\bar\alpha_t}\,x_0 \;+\; \sqrt{1-\bar\alpha_t}\,\varepsilon,\quad \varepsilon\sim\mathcal N(0,I).
$$

解释：$$x_t$$ 就是“信号 $$x_0$$” + “噪声”，而信噪比由 $$\bar\alpha_t$$ 控制；$$t$$ 越大，$$\bar\alpha_t$$ 越小，噪声占比越高。这个式子让我们**随机抽一个 t**、直接合成 $$(x_0,x_t)$$ 训练一条项，大幅加速训练。

---

## 5) 低方差的 KL 分解：式 (5)

把 (3) 进一步用 KL 分解改写成三块：

$$
L \;=\; 
\underbrace{\mathbb E\!\left[\mathrm{KL}\!\big(q(x_T\!\mid x_0)\,\|\,p(x_T)\big)\right]}_{L_T}
\;+\;
\underbrace{\sum_{t>1}\mathbb E\!\left[\mathrm{KL}\!\big(q(x_{t-1}\!\mid x_t,x_0)\,\|\,p_\theta(x_{t-1}\!\mid x_t)\big)\right]}_{L_{1:T-1}}
\;-\;
\underbrace{\mathbb E\![\log p_\theta(x_0\!\mid x_1)]}_{L_0}.
$$

**含义：**

* $$L_T$$：把最末端的 $$x_T$$ 推到标准正态（与先验匹配）。
* $$L_{1:T-1}$$：让**学到的去噪条件** $$p_\theta(x_{t-1}\!\mid x_t)$$ 逼近**正向过程的真实后验** $$q(x_{t-1}\!\mid x_t,x_0)$$。
* $$L_0$$：最后一步的“解码”项（论文后续把它做成离散解码器以得到离散数据的对数似然）。
  这个重写的好处是：所有 KL 都是**高斯与高斯**的比较，可闭式算、方差小。&#x20;

---

## 6) **正向后验**的闭式形式：式 (6)–(7)

关键一步是显式写出

$$
q(x_{t-1}\mid x_t, x_0)=\mathcal N\!\big(\tilde\mu_t(x_t,x_0),\, \tilde\beta_t I\big),
$$

其中

$$
\tilde\mu_t(x_t,x_0)=
\frac{\sqrt{\bar\alpha_{t-1}}\beta_t}{1-\bar\alpha_t}\,x_0
\;+\;
\frac{\sqrt{\alpha_t}(1-\bar\alpha_{t-1})}{1-\bar\alpha_t}\,x_t,
\qquad
\tilde\beta_t=\frac{1-\bar\alpha_{t-1}}{1-\bar\alpha_t}\,\beta_t.
$$

这些系数来自“线性高斯链的条件高斯”标准公式：它把**来自 $$x_0$$ 的先验信息**与**来自当前观测 $$x_t$$ 的似然信息**按方差加权做线性融合，因此均值是 $$x_0$$ 与 $$x_t$$ 的凸组合，方差 $$\tilde\beta_t$$ 则比单步噪声 $$\beta_t$$ 更小（因为条件化降低不确定性）。

> 直觉再补充：
> 若 $$\bar\alpha_t$$ 很小（大步数，信号很弱），则 $$(1-\bar\alpha_t)\approx 1$$，$$\tilde\mu_t$$ 更倚重 $$x_t$$ 中的观测项；而当 $$t$$ 小（靠近数据端，信号强），$$\tilde\mu_t$$ 对 $$x_0$$ 的权重上升。

---

## 7) 为什么这一切训练起来“很稳且高效”？

* **任取 t 采样训练**：借助式 (4) 的闭式，我们能在任意 $$t$$ 直接采到 $$(x_0,x_t)$$，于是 (5) 的每一项都可以随机抽样、做 SGD。&#x20;
* **KL 全是高斯对高斯**：有式 (6)(7)，所以 $$L_{1:T-1}$$ 的 KL 都闭式可算，降低估计方差，训练更稳定。
* **高斯同形性**：把正向链设为小步高斯（式 (2)），保证逆向链也能用高斯很好地刻画（模型表达力与目标分布的“函数形状”对齐）。

---

## 8) 一页小推导（式 (4) 的来龙去脉）

由 (2) 写作增量形式：

$$
x_t=\sqrt{\alpha_t}\,x_{t-1}+\sqrt{\beta_t}\,z_t,\; z_t\!\sim\!\mathcal N(0,I).
$$

递推展开：

$$
x_t=\Big(\prod_{s=1}^t\sqrt{\alpha_s}\Big)x_0
\;+\;
\sum_{k=1}^{t}\Big(\sqrt{\beta_k}\prod_{s=k+1}^{t}\sqrt{\alpha_s}\Big)z_k
\;=\;\sqrt{\bar\alpha_t}\,x_0+\text{(高斯和)}.
$$

由于独立高斯之和仍为高斯，且总方差
$$\sum_k \beta_k\prod_{s=k+1}^t\alpha_s = 1-\bar\alpha_t$$，便得到式 (4)。这也解释了重参数化采样 $$x_t=\sqrt{\bar\alpha_t}x_0+\sqrt{1-\bar\alpha_t}\varepsilon$$ 的来源。

---

## 9) 这些背景为后文铺路

上述分解直接引向第 3 节里常见的两种参数化与目标：

* **直接回归 $$\tilde\mu_t$$**（最朴素）；
* **等价改写为回归噪声 $$\varepsilon$$**（把 $$L$$ 化成“多噪声尺度的去噪分数匹配”型目标，采样像是**退火的 Langevin**）。这些都是在 (8)–(12) 推出来的，但属于下一节内容，这里点到为止。  &#x20;

---

### 一句话总括

* 把“造数据”变成“从高斯噪声逐步去噪”的链；
* 把“训练”变成“让学到的去噪一步步逼近**正向扩散**的真实后验”；
* 借助线性高斯链的闭式（式 (4)(6)(7)），训练**高效且稳定**，并为后面的 ε-预测目标奠定基础。&#x20;

---


## 下面把 **式 (5)** 的推导一步到位写清楚（对应论文附录 *Extended derivations* 给出的等式 (17)→(22) 的展开）。核心思路：从 ELBO 出发，按时间步重排、对 $$t=1$$ 单独拆分，再用一个 **Bayes 恒等式** 做“通项化简 + 望远（telescoping）消去”，最后把各项认成 KL。


### 第 0 步：从 ELBO 出发

先写出训练时用到的变分上界（ELBO）的紧凑形式（论文式 (17)）：

$$
L \;=\; \mathbb{E}_{q}\!\left[-\log \frac{p_\theta(x_{0:T})}{q(x_{1:T}\mid x_0)}\right].
$$

把联合分布与前向马尔可夫展开代入（式 (1)(2)），得到（论文式 (18)）：

$$
L
= \mathbb{E}_{q}\!\Bigg[
-\log p(x_T)\;-\sum_{t\ge 1}\log\frac{p_\theta(x_{t-1}\mid x_t)}{q(x_t\mid x_{t-1})}
\Bigg].
\;\; \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, 
\text{:contentReference[oaicite:0]{index=0}  :contentReference[oaicite:1]{index=1}}
$$

### 第 1 步：把 $$t=1$$ 单独拎出来

把求和中 $$t=1$$ 的那一项单独写成 $$-\log \tfrac{p_\theta(x_0\mid x_1)}{q(x_1\mid x_0)}$$，剩下求和范围改为 $$t>1$$（论文式 (19)）：

$$
L
= \mathbb{E}_{q}\!\Bigg[
-\log p(x_T)\;-\sum_{t>1}\log\frac{p_\theta(x_{t-1}\mid x_t)}{q(x_t\mid x_{t-1})}
\;-\log\frac{p_\theta(x_0\mid x_1)}{q(x_1\mid x_0)}
\Bigg].
\;\;\;\text{:contentReference[oaicite:2]{index=2}}
$$

### 第 2 步（关键）：Bayes 恒等式替换每个 $$q(x_t\mid x_{t-1})$$

利用前向链的联合分解

$$
q(x_{t-1},x_t\mid x_0)
= q(x_t\mid x_{t-1})\,q(x_{t-1}\mid x_0)
= q(x_{t-1}\mid x_t, x_0)\,q(x_t\mid x_0),
$$

得到恒等式

$$
q(x_t\mid x_{t-1})
= \frac{q(x_{t-1}\mid x_t,x_0)\,q(x_t\mid x_0)}{q(x_{t-1}\mid x_0)}.
$$

把它代入上式中所有 $$t>1$$ 的分母项（论文式 (20)）：

$$
\log\frac{p_\theta(x_{t-1}\mid x_t)}{q(x_t\mid x_{t-1})}
= \log\frac{p_\theta(x_{t-1}\mid x_t)}{q(x_{t-1}\mid x_t,x_0)}
\;+\;\log\frac{q(x_{t-1}\mid x_0)}{q(x_t\mid x_0)}.
$$

整体替换到 $$L$$ 里：

$$
L
= \mathbb{E}_{q}\!\Bigg[
-\log p(x_T)\;-\sum_{t>1}\Big(
\log\frac{p_\theta(x_{t-1}\mid x_t)}{q(x_{t-1}\mid x_t,x_0)}
+\log\frac{q(x_{t-1}\mid x_0)}{q(x_t\mid x_0)}
\Big)
\;-\log\frac{p_\theta(x_0\mid x_1)}{q(x_1\mid x_0)}
\Bigg].
\;\;\;\text{:contentReference[oaicite:3]{index=3}}
$$

### 第 3 步：望远消去，凑出两端项

注意第二个对数和是**望远和**：

$$
\sum_{t>1}\log\frac{q(x_{t-1}\mid x_0)}{q(x_t\mid x_0)}
= \log q(x_1\mid x_0) - \log q(x_T\mid x_0).
$$

把它与前后两端的项合并：

* 前端：$$-\log p(x_T)$$ 与 $$-\big(-\log q(x_T\mid x_0)\big)$$ 合起来变成

$$
-\log\frac{p(x_T)}{q(x_T\mid x_0)} = \log\frac{q(x_T\mid x_0)}{p(x_T)}.
$$

* 另一端：$$-\log \tfrac{p_\theta(x_0\mid x_1)}{q(x_1\mid x_0)}$$ 再加上望远和里留下的 $$+\log q(x_1\mid x_0)$$，刚好把 $$q(x_1\mid x_0)$$ 抵消，只剩 $$-\log p_\theta(x_0\mid x_1)$$。
  整理后得到（论文式 (21)）：

$$
L
= \mathbb{E}_{q}\!\Bigg[
-\log\frac{p(x_T)}{q(x_T\mid x_0)}
\;-\sum_{t>1}\log\frac{p_\theta(x_{t-1}\mid x_t)}{q(x_{t-1}\mid x_t,x_0)}
\;-\log p_\theta(x_0\mid x_1)
\Bigg].
\;\;\;\text{:contentReference[oaicite:4]{index=4}}
$$

### 第 4 步：把“对数比”认作 KL

最后一步只是把“期望的对数比”认作 KL：

$$
\mathbb{E}\!\left[-\log\frac{p}{q}\right] 
= \mathbb{E}\!\left[\log\frac{q}{p}\right] 
= D_{\mathrm{KL}}(q\Vert p).
$$

于是得到（论文式 (22)）也就是正文的 **式 (5)**：

$$
\boxed{
L = \mathbb{E}\!\Big[
\underbrace{D_{\mathrm{KL}}\!\big(q(x_T\!\mid x_0)\,\Vert\,p(x_T)\big)}_{L_T}
\;+\;
\underbrace{\sum_{t>1} D_{\mathrm{KL}}\!\big(q(x_{t-1}\!\mid x_t,x_0)\,\Vert\,p_\theta(x_{t-1}\!\mid x_t)\big)}_{L_{1:T-1}}
\;-\;
\underbrace{\log p_\theta(x_0\!\mid x_1)}_{L_0}
\Big].
}
\;\;\;\text{:contentReference[oaicite:5]{index=5}  :contentReference[oaicite:6]{index=6}
}
$$

> 小结直觉：
>
> * **中间项**是在每个步长上把**学到的去噪条件** $$p_\theta(x_{t-1}\!\mid x_t)$$ 和**真实前向后验** $$q(x_{t-1}\!\mid x_t,x_0)$$ 做 KL 匹配；
> * **两端**形成：把最末端 $$x_T$$ 推向先验 $$p(x_T)$$ 的 KL，以及最后一步（从 $$x_1$$ 解码回数据）的对数似然项。

另外，由于 $$q(x_{t-1}\!\mid x_t,x_0)$$ 本身是**线性高斯链的条件高斯**，其均值/方差是闭式（论文式 (6)(7)），因此上式里的所有 KL 都是“高斯对高斯”，可闭式、低方差地估计：

$$
q(x_{t-1}\!\mid x_t,x_0)=\mathcal N\!\big(\tilde\mu_t(x_t,x_0),\,\tilde\beta_t I\big).
\;\;\;\text{:contentReference[oaicite:7]{index=7}  :contentReference[oaicite:8]{index=8}
}
$$

## 下面补充一点：DDPM 的采样更新 $$\mu_\theta$$（式 (1) 中的均值）为什么可以看成**Langevin/score-based 反向扩散**的一步？

短答：基本可以把它看成**Langevin/score-based 反向更新**的离散版本。更准确地说，$$\mu_\theta$$ 里减去的那一项在用 $$\varepsilon_\theta$$ 近似**分数函数**（score）$$\nabla_{x_t}\log q_t(x_t)$$，从而形成“沿着对数密度上升方向走一步”的校正，再加上高斯噪声完成一步**反向扩散**。

---

## 1) 先把 $$\varepsilon_\theta$$ 和 score 对上

已知（高斯加噪的恒等式）：

$$
x_t=\sqrt{\bar\alpha_t}\,x_0+\sqrt{1-\bar\alpha_t}\,\varepsilon,\qquad 
\varepsilon\sim\mathcal N(0,I).
$$

对任意高斯 $$q_t(x_t)$$，其**分数函数**满足

$$
\nabla_{x_t}\log q_t(x_t)\;=\;-\frac{1}{\sqrt{1-\bar\alpha_t}}\;\mathbb E[\varepsilon\mid x_t].
$$

训练 $$\varepsilon_\theta$$ 用 MSE 时的最优解是 $$\varepsilon_\theta(x_t,t)\approx \mathbb E[\varepsilon\mid x_t]$$，
于是得到常用等价式：

$$
\varepsilon_\theta(x_t,t)\;\approx\;-\sqrt{1-\bar\alpha_t}\;\nabla_{x_t}\log q_t(x_t).
$$

---

## 2) 把 $$\mu_\theta$$ 写成“梯度上升一步”

$$
\mu_\theta
= \frac{1}{\sqrt{\alpha_t}}\Big(
x_t-\frac{\beta_t}{\sqrt{1-\bar\alpha_t}}\varepsilon_\theta
\Big)
\;\;\stackrel{(\*)}{\approx}\;\;
\frac{1}{\sqrt{\alpha_t}}\Big(
x_t + \beta_t\,\nabla_{x_t}\log q_t(x_t)
\Big).
$$

其中 $$(\*)$$ 把上面的 $$\varepsilon_\theta\to$$ score 替换代入。
这正是“**沿着 $$\nabla\log q_t$$ 做一步梯度上升**（步长 $$\beta_t$$），再乘上一个预条件因子 $$1/\sqrt{\alpha_t}$$”的形式。

---

## 3) 和 Langevin/反向 SDE 的关系

* **Langevin（离散）**：$$x\leftarrow x+\eta\,\nabla_x\log p(x)+\sqrt{2\eta}\,z$$。
* \*\*Score-based 反向 SDE（VP 家族）\*\*的欧拉步也形如
  $$x_{t-1}\approx x_t + \underbrace{\text{drift}(x_t,t)}_{\propto \nabla\log q_t(x_t)} + \text{noise}$$。

DDPM 的一步：

$$
x_{t-1}=\mu_\theta+\sqrt{\tilde\beta_t}\,z
\approx
\frac{1}{\sqrt{\alpha_t}}\!\left[x_t+\beta_t\,\nabla\log q_t(x_t)\right]
+\sqrt{\tilde\beta_t}\,z,
$$

可以看作是**预条件（$$1/\sqrt{\alpha_t}$$）+ 梯度上升（$$\beta_t$$ 步长）+ 退火噪声（$$\tilde\beta_t$$）**的**Langevin-like** 更新。
区别只在于：DDPM 来自**离散化的逆马尔可夫链**（方差保留/VP 族），系数与 $$\alpha_t,\bar\alpha_t,\beta_t$$ 的日程紧密耦合；而经典 Langevin 用的是固定 $$\eta$$。

---

## 4) 直觉

* $$t$$ 大（噪声重）时，$$\beta_t$$ 通常更大 → **更大胆**地朝着高密度方向推进；
* 越接近数据端，$$\beta_t$$ 小、噪声也小 → **更谨慎**地微调到流形上；
* 预条件 $$1/\sqrt{\alpha_t}$$ 来自 **VP 过程** 的解析逆均值，是把“去噪”的线性漂移与“梯度校正”合在一起。

> 所以，括号里的“后半段”确实可以理解为 **Langevin 的梯度项**（沿 $$\nabla\log q_t$$ 的上升），只是系数被扩散日程预条件化了，完整一步还需加上对应的高斯噪声。
