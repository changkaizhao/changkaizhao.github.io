<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Robys AI Lab</title>
    <description>Create a mind never fade.</description>
    <link>http://www.digitbrain.science//</link>
    <atom:link href="http://www.digitbrain.science//feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 11 Jul 2018 20:44:08 +0800</pubDate>
    <lastBuildDate>Wed, 11 Jul 2018 20:44:08 +0800</lastBuildDate>
    <generator>Jekyll v3.8.3</generator>
    
      <item>
        <title>How to save numpy array to tfrecord and load via TFSlim dataset pipeline</title>
        <description>&lt;p&gt;This tutorial shows how to save numpy array to &lt;code class=&quot;highlighter-rouge&quot;&gt;tfrecord&lt;/code&gt; file a tensorflow dataset format, and load numpy array from tfrecord with &lt;code class=&quot;highlighter-rouge&quot;&gt;TFSlim&lt;/code&gt; dataset pipeline.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;!!! &lt;code class=&quot;highlighter-rouge&quot;&gt;TFSLIM&lt;/code&gt; is deprecated from tensorflow r1.9&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;save-numpy-array-to-tfrecord&quot;&gt;Save numpy array to tfrecord&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;saveDataToTFRecord.py&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;
#Save numpy data to tfrecord

import numpy as np
import tensorflow as tf

#Generate Test data
# a float array and int array each with shape (2,2,2)

f_array = np.array([[[1., 2.],
                     [3., 4.]],

                    [[5., 6.],
                     [7., 8.]]], dtype=np.float)

i_array = np.array([[[10, 11],
                     [12, 13]],

                    [[14, 15],
                     [16, 17]]], dtype=np.int64)



#we have to reshape array to 1-D array before saving
f_array = np.reshape(f_array, [2*2*2,])
i_array = np.reshape(i_array, [2*2*2,])


output_filename = &quot;/Development/tensorflow/tensorflowTest/dataloadTest/&quot; \
                  &quot;testdata.tfrecord&quot;

writer = tf.python_io.TFRecordWriter(output_filename)


def float_feature(value):
    return tf.train.Feature(float_list=tf.train.FloatList(value=value))

def int64_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))

feature_dict = {
    'i_array': int64_feature(i_array),
    'f_array': float_feature(f_array),
}

example = tf.train.Example(features=tf.train.Features(feature=feature_dict))

writer.write(example.SerializeToString())
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;load-data-from-tfrecord-via-tfslim-data-pipeline&quot;&gt;Load data from tfrecord via TFSlim data pipeline&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;loaddatafromtfrecord.py&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;
#Load data from TFRecord via TFSlim data pipeline

import tensorflow as tf
from tensorflow.contrib import slim

data_file = &quot;/Development/tensorflow/tensorflowTest/dataloadTest/&quot; \
                  &quot;testdata.tfrecord&quot;
reader = tf.TFRecordReader

keys_to_features = {
    'i_array' : tf.FixedLenFeature([2*2*2], dtype=tf.int64),
    'f_array' : tf.FixedLenFeature([2*2*2], dtype=tf.float32)
}

items_to_handlers = {
    'i_array' : slim.tfexample_decoder.Tensor('i_array'),
    'f_array' : slim.tfexample_decoder.Tensor('f_array')
}

items_to_descriptions = {
    'i_array' : 'a 2X2X2 int64 array',
    'f_array' : 'a 2X2X2 float32 array'
}
decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features,
                                                  items_to_handlers)

dataset = slim.dataset.Dataset(data_sources=data_file, reader=reader,
                               decoder=decoder, num_samples=2,
                               items_to_descriptions=items_to_descriptions)

provider = slim.dataset_data_provider.DatasetDataProvider(
    dataset, num_readers=1, common_queue_capacity=100, common_queue_min=4)

[i_array, f_array] = provider.get(['i_array', 'f_array'])

# we should reshape again ,to restore original shape of array
i_array = tf.reshape(i_array, [2, 2, 2])
f_array = tf.reshape(f_array, [2, 2, 2])

b_iarray, b_farray = tf.train.batch([i_array, f_array], batch_size=1,
                                    num_threads=1, capacity=5)

batch_queue = slim.prefetch_queue.prefetch_queue([b_iarray, b_farray],
                                                 capacity=1)

sess = tf.Session()
thread = tf.train.start_queue_runners(sess=sess)

iarray, farray = batch_queue.dequeue()
ia, fa = sess.run([iarray, farray])

print(ia[0])
print(fa[0])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;will print results as below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;
 [[[10 11]
  [12 13]]

  [[14 15]
   [16 17]]]
   
 [[[1. 2.]
   [3. 4.]]

  [[5. 6.]
   [7. 8.]]]
   &lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;we can see the results are all expected!&lt;/p&gt;
</description>
        <pubDate>Wed, 11 Jul 2018 00:00:00 +0800</pubDate>
        <link>http://www.digitbrain.science//2018/07/11/How-to-save-numpy-array-to-tfrecord-and-load-by-TFSlim-dataset-pipeline.html</link>
        <guid isPermaLink="true">http://www.digitbrain.science//2018/07/11/How-to-save-numpy-array-to-tfrecord-and-load-by-TFSlim-dataset-pipeline.html</guid>
        
        <category>tensorflow</category>
        
        <category>slim</category>
        
        <category>tfrecord</category>
        
        
        <category>技术</category>
        
      </item>
    
      <item>
        <title>MathJax Test</title>
        <description>&lt;p&gt;mathjax in markdown :)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这是一个不&lt;code class=&quot;highlighter-rouge&quot;&gt;align&lt;/code&gt;的公式&lt;/strong&gt;：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\forall \alpha \in A, \quad a \cdot b = 0&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;这是一个&lt;code class=&quot;highlighter-rouge&quot;&gt;align&lt;/code&gt;的公式&lt;/strong&gt;：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\text{for OTP : $\qquad$ if }\quad E(k,\:m)=c\\
\begin{align}
k\oplus m &amp;= c \\
k &amp;= m\oplus c
\end{align}
\\
\#\{\;k \in \mathscr K : \quad E(k,\:m)=c \;\}=1 \quad \forall m,\:c %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;公式块要想有较好的显示效果，必须在公式块标记符&lt;code class=&quot;highlighter-rouge&quot;&gt;$$&lt;/code&gt;&lt;strong&gt;前后&lt;/strong&gt;留有空行，否则公式将不能正常居中。行内公式无此问题。&lt;/p&gt;
</description>
        <pubDate>Sun, 30 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://www.digitbrain.science//2017/07/30/mathjax-test.html</link>
        <guid isPermaLink="true">http://www.digitbrain.science//2017/07/30/mathjax-test.html</guid>
        
        <category>mathjax</category>
        
        
        <category>test</category>
        
      </item>
    
      <item>
        <title>Synaptic Connectivity Motifs Contribute to Efficient Memory Retrieval in Hippocampus ( *突触连接样式有助于在海马体内记忆的有效检索* )</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;原文：&lt;a href=&quot;http://neurosciencenews.com/hippocampus-synaptic-connection-memory-5027/&quot;&gt;Synaptic Connectivity Motifs Contribute to Efficient Memory Retrieval in Hippocampus&lt;/a&gt;&lt;/p&gt;

  &lt;p&gt;翻译：Roby&lt;/p&gt;

  &lt;p&gt;来源：IST Austria（奥地利科技学院）&lt;/p&gt;

  &lt;p&gt;摘要：研究人员结合功能连接分析(&lt;em&gt;functional connectivity analyis&lt;/em&gt;)和网络建模(&lt;em&gt;network modeling&lt;/em&gt;)方法来研究&lt;strong&gt;海马体&lt;/strong&gt;内&lt;strong&gt;CA3网络&lt;/strong&gt;模式生成的突触连接机制。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;海马体&lt;/strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;CA3&lt;/code&gt;区在学习和记忆过程中起着关键作用。&lt;code class=&quot;highlighter-rouge&quot;&gt;CA3&lt;/code&gt;区的神经网络的一个最重要的功能是它可以检索之前存储在记忆中的不完整或降级版本，也就是被人熟知的&lt;strong&gt;模式生成&lt;/strong&gt;(&lt;em&gt;pattern completion&lt;/em&gt;)。人们普遍认为&lt;code class=&quot;highlighter-rouge&quot;&gt;CA3&lt;/code&gt;区神经网络内的锥形神经元细胞之间的突触 (重复的&lt;code class=&quot;highlighter-rouge&quot;&gt;CA3-CA3&lt;/code&gt;突触)，在模式生成过程中起到了关键作用，但其内部运作机理目前仍然不清晰。最近的一篇研究文章题为“&lt;strong&gt;Synaptic Connectivity Motifs Contribute to Efficient Memory Retrieval in Hippocampus&lt;/strong&gt;”于2016年9月9日发表在&lt;strong&gt;Science&lt;/strong&gt;，作者&lt;em&gt;Jose Guzman, Alois Schlögl, Michael Frotscher&lt;/em&gt;  和 &lt;em&gt;Peter Jonas&lt;/em&gt;通过结合&lt;strong&gt;功能连接分析&lt;/strong&gt;和&lt;strong&gt;网络建模&lt;/strong&gt;来研究上述运作机理。他们的研究结果表明，&lt;code class=&quot;highlighter-rouge&quot;&gt;CA3&lt;/code&gt;区神经网络锥形神经元之间的突触连接的方式对&lt;strong&gt;模式生成&lt;/strong&gt;效率的影响极其显著。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/changkaizhao/changkaizhao.github.io/master/images/2016-9-13/1.jpg&quot; alt=&quot;突触连接&quot; /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;CA3&lt;/code&gt;区锥形&lt;strong&gt;神经元对&lt;/strong&gt;突触连接重建图。图中为由单个突触连接的&lt;strong&gt;神经元对&lt;/strong&gt;的显微图像。NeuroscienceNews.com image is adapted from the IST Austria press release.&lt;/p&gt;

&lt;p&gt;早前对于&lt;strong&gt;海马体&lt;/strong&gt;构成的理论认为&lt;code class=&quot;highlighter-rouge&quot;&gt;CA3&lt;/code&gt;区的神经网络内部的神经元也是高度相互连接的。奥地利科技学院的神经科学家通过同时监控8个相互连接的神经元之间的电信号传导的方法来检验早前的假设。经过实验后，结果让人很震惊,首先他们发现此区域中的神经元连接是稀疏的，平均连接概率约为&lt;code class=&quot;highlighter-rouge&quot;&gt;1%&lt;/code&gt;。这对于之前死板地认为神经网络的神经元是高度连接的结论提出了极大的挑战。令人更加惊讶的是，网络内部神经元的连接也不是随机的，相对于随机神经网络其内部神经元连接更多地呈现某种&lt;strong&gt;样式&lt;/strong&gt;(&lt;em&gt;motifs&lt;/em&gt;)。因此，&lt;strong&gt;海马体&lt;/strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;CA3&lt;/code&gt;区的神经元连接结构某种程度上让人联想到社交网络中的&lt;em&gt;“小世界”&lt;/em&gt;(small world)结构。最后，作者发现这个区域中的两个神经元间的突触连接仅有&lt;code class=&quot;highlighter-rouge&quot;&gt;1&lt;/code&gt;到&lt;code class=&quot;highlighter-rouge&quot;&gt;2&lt;/code&gt;个。要知道在&lt;strong&gt;新大脑皮层&lt;/strong&gt;(&lt;em&gt;neocortex&lt;/em&gt;)中的神经元之间刺激性突触连接个数远大于&lt;code class=&quot;highlighter-rouge&quot;&gt;2&lt;/code&gt;个。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这些极特殊的突触连接方式具有什么功能，尤其对模式生成有什么关系？&lt;/strong&gt;为了回答这个问题，&lt;em&gt;Peter Jonas&lt;/em&gt;和他的团队根据他们的实验发现搭建了一个&lt;code class=&quot;highlighter-rouge&quot;&gt;CA3&lt;/code&gt;神经网络模型。跟之前的研究不同，这次构建的神经网络是全尺寸的，因此老鼠&lt;strong&gt;海马体&lt;/strong&gt;内&lt;code class=&quot;highlighter-rouge&quot;&gt;330，000&lt;/code&gt;个&lt;code class=&quot;highlighter-rouge&quot;&gt;CA3&lt;/code&gt;区的神经元全部被模拟出来。这个建模方式占用了大量奥地利科技学院计算机集群的计算能力，同时也获得了学院科学技术服务部门&lt;em&gt;“科学计算”&lt;/em&gt;的大力支持。作者发现跟真实大脑一样连接率&lt;code class=&quot;highlighter-rouge&quot;&gt;1%&lt;/code&gt;全尺寸的神经网络模型确实能够进行&lt;strong&gt;模式生成&lt;/strong&gt;的网络计算。此外，在特定条件下，出现的连接动机增加了神经网络的性能。最后，基于1到2个神经突触连接方式设计的模型看起来对于&lt;strong&gt;模式生成&lt;/strong&gt;也是很有帮助，显然因为信息在神经网络中传递的冗余被减小。这样宏观连接(例如&lt;strong&gt;样式&lt;/strong&gt; &lt;em&gt;motifs&lt;/em&gt;)和微观连接(例如&lt;strong&gt;连接属性&lt;/strong&gt; &lt;em&gt;properties of connection&lt;/em&gt;)对于&lt;code class=&quot;highlighter-rouge&quot;&gt;CA3&lt;/code&gt;区神经网络的&lt;strong&gt;模式生成&lt;/strong&gt;都起到了作用。&lt;strong&gt;“实验结果证明了&lt;em&gt;Hopfield&lt;/em&gt;的名言“&lt;em&gt;只有亲手建造过，才会理解其原理&lt;/em&gt;” 在神经网络关键问题的研究中是一个成功的方法论” &lt;em&gt;Peter Jonas&lt;/em&gt;_&lt;/strong&gt; 说，其领导整个细胞神经科学小组。&lt;/p&gt;
</description>
        <pubDate>Tue, 13 Sep 2016 00:00:00 +0800</pubDate>
        <link>http://www.digitbrain.science//2016/09/13/Synaptic-Connectivity-Motifs-Contribute-to-Efficient-Memory-Retrieval-in-Hippocampus.html</link>
        <guid isPermaLink="true">http://www.digitbrain.science//2016/09/13/Synaptic-Connectivity-Motifs-Contribute-to-Efficient-Memory-Retrieval-in-Hippocampus.html</guid>
        
        
      </item>
    
  </channel>
</rss>
